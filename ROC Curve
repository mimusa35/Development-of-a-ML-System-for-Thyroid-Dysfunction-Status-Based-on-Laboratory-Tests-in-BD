class_labels = ['Hyper', 'Hypo', 'Normal', 'Sick-eu']
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)

dt_classifier = DecisionTreeClassifier(criterion='entropy', max_depth=7, min_samples_split=25, min_samples_leaf=3, min_impurity_decrease=0.0, random_state=0)
sgb_classifier = GradientBoostingClassifier(random_state=42, n_estimators=40, criterion='friedman_mse', max_depth=3, learning_rate=0.1, min_samples_split=50, min_samples_leaf=4)
xgb_classifier = XGBClassifier(random_state=0, n_estimators=110, max_depth=2, learning_rate=0.1)
catboost_classifier = CatBoostClassifier(n_estimators=50, max_depth=7, verbose=False, random_state=55, learning_rate=0.2)
rf_classifier = RandomForestClassifier(criterion='gini', max_depth=9, max_features='auto', n_estimators=55, random_state=35)

voting_classifier = VotingClassifier(estimators=[
    ('DT', dt_classifier),
    ('SGB', sgb_classifier),
    ('XGBoost', xgb_classifier),
    ('RF', rf_classifier)
], voting='soft')

classifiers = {
    "DT": dt_classifier,
    "SGB": sgb_classifier,
    "XGBoost": xgb_classifier,
    "RF": rf_classifier,
    "CatBoost": catboost_classifier,
    "Voting": voting_classifier
}

plt.figure(figsize=(8, 6))

for clf_name, classifier in classifiers.items():
    classifier.fit(X_train, y_train_encoded)

    y_probs = classifier.predict_proba(X_test)

    for i, label in enumerate(class_labels):
        class_indices = (y_test == label)
        fpr, tpr, _ = roc_curve(class_indices, y_probs[:, i])
        roc_auc = auc(fpr, tpr)

        plt.plot(fpr, tpr, label=f'{clf_name} - {label} (area = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc="lower right", bbox_to_anchor=(1.6, 0), ncol=1, fontsize=10)
plt.show()
