X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
dt_classifier = DecisionTreeClassifier(criterion='entropy', max_depth=7, min_samples_split=25, min_samples_leaf=3, min_impurity_decrease=0.0, random_state=0)
sgb_classifier = GradientBoostingClassifier(random_state=42, n_estimators=40, criterion='friedman_mse', max_depth=3, learning_rate=0.1, min_samples_split=50, min_samples_leaf=4)
xgb_classifier = XGBClassifier(random_state=0, n_estimators=110, max_depth=2, learning_rate=0.1)
rf_classifier = RandomForestClassifier(criterion='gini', max_depth=9, max_features='auto', n_estimators=55, random_state=35)


voting_classifier = VotingClassifier(estimators=[('DT', dt_classifier), ('SGB', sgb_classifier), ('XGBoost', xgb_classifier), ('RF', rf_classifier)],
                                     voting='soft')
voting_classifier.fit(X_train, y_train)
y_pred = voting_classifier.predict(X_test)

target_names = ['Normal', 'Hypo', 'Hyper', 'Sick-euthyroidism']
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)

tn = conf_matrix[0, 0]
fp = conf_matrix[0, 1] + conf_matrix[0, 2] + conf_matrix[0, 3]
fn = conf_matrix[1, 0] + conf_matrix[2, 0] + conf_matrix[3, 0]
tp = conf_matrix[1, 1] + conf_matrix[1, 2] + conf_matrix[1, 3] + conf_matrix[2, 1] + conf_matrix[2, 2] + conf_matrix[2, 3] + conf_matrix[3, 1] + conf_matrix[3, 2] + conf_matrix[3, 3]

precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=target_names))
